# ----------------------------
# Configurações do provedor LLM
# ----------------------------

# Define qual provedor de IA será utilizado pelo backend.
# Opções válidas: "gemini" (padrão) ou "openai".
LLM_PROVIDER=gemini

# ----------------------------
# Credenciais e modelos Gemini
# ----------------------------

# Obrigatório quando LLM_PROVIDER=gemini. Chave de API do Google Gemini.
GEMINI_API_KEY=

# Modelo multimodal usado para gerar sugestões de texto.
# Valor sugerido: gemini-2.5-flash
#GEMINI_SUGGESTION_MODEL=gemini-2.5-flash

# Modelo usado para gerar/editar imagens de cabelo.
# Valor sugerido: gemini-2.5-flash-image-preview
#GEMINI_IMAGE_MODEL=gemini-2.5-flash-image-preview

# ---------------------------
# Credenciais e modelos OpenAI
# ---------------------------

# Obrigatório quando LLM_PROVIDER=openai. Chave de API da OpenAI.
#OPENAI_API_KEY=

# Modelo de texto/visão usado para sugestões de penteado.
# Exemplos: gpt-4o-mini, gpt-4.1-mini
#OPENAI_SUGGESTION_MODEL=gpt-4o-mini

# Modelo de geração de imagens utilizado para aplicar o novo cabelo.
# Exemplo mais comum: gpt-image-1
#OPENAI_IMAGE_MODEL=gpt-image-1

# ----------------------------------------
# Configurações gerais de servidor/cliente
# ----------------------------------------

# Porta opcional do servidor backend (padrão: 3001)
#PORT=3001

# Origem permitida para requisições diretas (padrão: *)
#CORS_ORIGIN=http://localhost:5173

# Base opcional utilizada pelo front-end para acessar o backend (padrão: /api)
#VITE_API_BASE_URL=http://localhost:3001/api
